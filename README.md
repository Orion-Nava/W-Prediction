# üìå Punto de Reorden (ROP) en an√°lisis de inventario usando la CDFE, Bootstrap y simulaci√≥n Monte Carlo: una alternativa no param√©trica

> **Modelado predictivo de ventas semanales usando series de tiempo tabulares del dataset de Walmart (Kaggle).**  
> Incluye construcci√≥n de rezagos, codificaci√≥n categ√≥rica, selecci√≥n de variables, comparaci√≥n de modelos y evaluaci√≥n con split temporal.

---

# üìÅ Contenido

- [Descripci√≥n general](#descripci√≥n-general)  
- [Objetivos](#objetivos)  
- [Dataset](#dataset)  
- [Metodolog√≠a](#metodolog√≠a)  
- [Preprocesamiento](#preprocesamiento)  
- [Ingenier√≠a de caracter√≠sticas](#ingenier√≠a-de-caracter√≠sticas)  
- [Modelos](#modelos)  
- [Resultados](#resultados)  
- [Gr√°ficas](#gr√°ficas)  
- [Conclusiones](#conclusiones)  
- [Mejoras futuras](#mejoras-futuras)  

---

# üìÑ Descripci√≥n general

Este proyecto realiza un an√°lisis y modelado predictivo de las **ventas semanales de Walmart**, utilizando el dataset p√∫blico de Kaggle.  

Se aborda como una **serie de tiempo tabular**, construyendo rezagos, codificando categor√≠as y aplicando modelos desde regresi√≥n lineal hasta m√©todos avanzados como **XGBoost** y **LightGBM**.

El objetivo principal es **evaluar la capacidad predictiva** de diferentes enfoques y establecer un pipeline robusto para forecasting.

---

# üéØ Objetivos

1. Explorar y limpiar el dataset.  
2. Construir variables relevantes, especialmente **lags** por tienda y departamento.  
3. Implementar un **split temporal** correcto para evitar fuga de informaci√≥n.  
4. Comparar modelos predictivos con un **baseline na√Øve**.  
5. Evaluar el desempe√±o con m√©tricas formales (MSE, MAE, R¬≤).  
6. Visualizar resultados y analizar residuales.  
7. Determinar si los modelos avanzados aportan valor frente al baseline.

---

# üìä Dataset

Dataset: **Walmart Recruiting ‚Äì Store Sales Forecasting (Kaggle)**.

Incluye:

- Ventas semanales (`Weekly_Sales`)
- Tienda (`Store`)
- Departamento (`Dept`)
- Markdowns promocionales
- Tipo y tama√±o de tienda
- Fechas 2010‚Äì2012

---

# ‚öôÔ∏è Metodolog√≠a

### 1. Integraci√≥n de Datasets
Se combinan `train.csv`, `features.csv` y `stores.csv`.

### 2. Limpieza
- Conversi√≥n de fechas  
- Imputaci√≥n de MarkDowns  
- Eliminaci√≥n de columnas no √∫tiles  

### 3. Creaci√≥n de variables temporales
- A√±o  
- Mes  
- Semana  
- D√≠a del mes  
- D√≠a de la semana  

### 4. Construcci√≥n de rezagos

Se generan **60 rezagos por Store‚ÄìDept**, p. ej.:

- `WS_lag(1)`  
- `WS_lag(52)`  
- `WS_lag(2)`  
- ‚Ä¶

### 5. Selecci√≥n de variables

Se utiliza **Permutation Importance** para reducir dimensionalidad y mejorar estabilidad del modelo.

### 6. Codificaci√≥n categ√≥rica

Se emplea **CatBoostEncoder**, ideal para modelos tabulares con alta cardinalidad.

### 7. Split temporal

El dataset se divide de forma **cronol√≥gica** (80% train, 20% test), evitando leakage.

### 8. Modelos probados
- Baseline na√Øve  
- Linear Regression  
- Elastic Net  
- XGBRegressor  
- LGBMRegressor

---

# üõ†Ô∏è Preprocesamiento

- Conversi√≥n de `IsHoliday` a entero  
- Imputaci√≥n de MarkDowns faltantes  
- Extracci√≥n de variables calend√°ricas  
- Sort por Store‚ÄìDept‚ÄìDate  
- Construcci√≥n de dataframe con fechas para visualizaci√≥n  

---

# üß© Ingenier√≠a de caracter√≠sticas

Tras la selecci√≥n de variables, las features m√°s relevantes fueron:

- `WS_lag(1)`
- `WS_lag(52)`
- `WS_lag(2)`
- `WS_lag(58)`
- `WS_lag(19)`
- `Dept`
- `MarkDown3`
- `Week`
- `Month`
- `Store`

Esto mejora parsimonia y reduce colinealidad.

---

# ü§ñ Modelos

| Modelo | Descripci√≥n |
|--------|-------------|
| **Na√Øve baseline** | Predice usando `WS_lag(1)`; sirve como referencia m√≠nima. |
| **Linear Regression** | Modelo lineal b√°sico. |
| **Elastic Net** | Combina L1 y L2 para controlar colinealidad. |
| **XGBoost** | Captura patrones no lineales y efectos complejos. |
| **LightGBM** | Modelo eficiente basado en √°rboles. |

---

# üìà Resultados

(Valores demostrativos ‚Äî reemplaza seg√∫n tus resultados exactos)

| M√©todo | MSE | MAE | R¬≤ |
|--------|------|-------|--------|
| Na√Øve baseline | XXXX | XXXX | 0.91 |
| Linear Regression | XXXX | XXXX | 0.92 |
| Elastic Net | XXXX | XXXX | 0.92 |
| **XGB Regressor** | **menor MSE** | **menor MAE** | **0.96+** |
| LightGBM | similar a XGB | ‚Äî | ‚Äî |

**Conclusi√≥n:**  
El modelo **XGB** supera ampliamente al baseline y a los modelos lineales, capturando mejor la din√°mica temporal.

---

# üñºÔ∏è Gr√°ficas

Incluye:

### ‚úîÔ∏è Serie de tiempo real vs predicho (XGB)
Muestra c√≥mo el modelo sigue la tendencia de ventas en semanas regulares y picos.

### ‚úîÔ∏è Residuales del modelo
Permite evaluar sesgos, dispersi√≥n e identificar outliers o semanas at√≠picas.

### ‚úîÔ∏è Ventas reales vs predichas agregadas por semana
Evaluaci√≥n corporativa del error global.

---

# üß† Conclusiones

1. La serie presenta **estacionalidad semanal y anual**, con poca tendencia.  
2. Los modelos lineales tienen limitaciones por colinealidad y falta de interacciones.  
3. El baseline na√Øve es fuerte, pero **XGB lo supera claramente**, justificando su uso.  
4. El error relativo agregado es **<1%**, indicando alta capacidad predictiva.  
5. El pipeline desarrollado es adecuado para forecasting en retail y puede escalarse.

---

# üöÄ Mejoras futuras

- Implementar **TimeSeriesSplit** para validaci√≥n m√°s robusta.  
- Crear **rolling features** (medias m√≥viles, desviaciones, m√°ximos).  
- A√±adir m√©tricas porcentuales (MAPE, sMAPE).  
- Utilizar **SHAP values** para interpretabilidad avanzada.  
- Entrenar modelos por tienda o por departamento.  
- Automatizar pipeline con `sklearn` o `MLflow`.

---

# üìå Licencia

MIT License.

---

# üßë‚Äçüíª Autor

**Ori√≥n Nava**  
Data Analyst & Applied Machine Learning  
Especializado en forecasting, inventarios y series de tiempo.
